{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project11_logisticregression_crossvalidation_breastcancer_Wisconsin.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGUNM2BEsBQ5",
        "colab_type": "text"
      },
      "source": [
        "# Project objective\n",
        "This project is designed to review logistic regression method and its python implementation using Wisconsin breast cancer dataset. Performance of the modeling will be assessed using k-fold cross validation for different k values.\n",
        "\n",
        "Information about the dataset, some technical details about the used machine learning method(s) and mathematical details of the quantifications approaches are provided in the code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjtJFxdsNh05",
        "colab_type": "text"
      },
      "source": [
        "# Packages we work with in this notebook\n",
        "We are going to use the following libraries and packages:\n",
        "\n",
        "* **numpy**: NumPy is the fundamental package for scientific computing with Python. (http://www.numpy.org/)\n",
        "* **sklearn**: Scikit-learn is a machine learning library for Python programming language. (https://scikit-learn.org/stable/)\n",
        "\n",
        "We also use **warnings** to stop the notebook from returning warning messages.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57oB2idEgr-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sklearn as sk\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb1Zm7ARN5D5",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to the dataset\n",
        "\n",
        "**Name**: Wisconsin breast cancer dataset\n",
        "\n",
        "**Summary**: Identifying if there is a malignant tumor or not using features that are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.\n",
        "\n",
        "**number of features**: 30 (real, positive) \n",
        "\n",
        "**Number of data points (instances)**: 569\n",
        "\n",
        "**dataset accessibility**: Dataset is available as part of sklearn package.\n",
        "\n",
        "**Link to the dataset**: http://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjBnejgpP0Gr",
        "colab_type": "text"
      },
      "source": [
        "## Loading the dataset and separating features and labels\n",
        "The dataset is available as part of sklearn package. Hence, we do not need to import the data directly from UCI ML repository. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RILQWrhjQUtF",
        "colab_type": "code",
        "outputId": "a2b6edb4-5f49-41a0-d8b3-4d2fb5538440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Loading breast cancer data\n",
        "target_dataset = load_breast_cancer()\n",
        "\n",
        "# separating feature arrays of pixel values (X) and labels (y) \n",
        "input_features = target_dataset.data\n",
        "output_var = target_dataset.target\n",
        "# printing number of features (pixels) and data points \n",
        "n_samples, n_features = input_features.shape\n",
        "print(\"number of samples (data points):\", n_samples)\n",
        "print(\"number of features:\", n_features)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples (data points): 569\n",
            "number of features: 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0Fi1jpVkbhC",
        "colab_type": "text"
      },
      "source": [
        "## Building the supervised learning model\n",
        "We want to build a binary classification model as the output variable is categorical with 2 classes. Here we build a simple logistic regression model.\n",
        "\n",
        "### Logistic regression\n",
        "If we have set of features X1 to Xn, y can be obtained as:\n",
        "\\begin{equation*} y=b0+b1X1+b2X2+...+bnXn\\end{equation*}\n",
        "\n",
        "where y is the predicted value obtained by weighted sum of the feature values.\n",
        "\n",
        "Then probability of each class (for example if there is a malignant tumor) can be obtained using the logistic function \n",
        "\n",
        "\\begin{equation*} p(class=malignant)=\\frac{1}{(1+exp(-y))} \\end{equation*}\n",
        "\n",
        "Based on the given class labels and the features given in the trainign data, coefficients b0 to bn can be ontained during the optimization process.\n",
        "\n",
        "b0 to bn are fixed for all samples while X1 to Xn are feature values specific to each sample. Hence, the logistic function will give us probability of each class assigned to each sample. Finally, the model will choose the class with the highest probability for each sample.\n",
        "\n",
        "\n",
        "**Note.** The logistic regression model is parametric and the parameters are the regression coefficiets b0 to bn."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GaWQgt52opOw",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating performance of the model\n",
        "We need to assess performance of the model using the predictions of the test set. We use accuracy and balanced accuracy. Here are their definitions:\n",
        "\n",
        "* **accuracy**: This measure gives you a sense of performance for all the classes together as follows:\n",
        "\n",
        "$$ {\\displaystyle {\\text{accuracy}}={\\frac {tp+tn}{tp+tn+fp+fn}}\\,}$$\n",
        "\n",
        "\n",
        "\\begin{equation*} accuracy=\\frac{number\\:of\\:correct\\:predictions}{(total\\:number\\:of\\:data\\:points (samples))} \\end{equation*}"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj3SSteMkxb2",
        "colab_type": "code",
        "outputId": "86005708-6c0b-4d0d-cbae-7fc01d922e18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.linear_model import LogisticRegression \n",
        "\n",
        "# Create logistic regression object\n",
        "logreg = LogisticRegression(random_state=10)\n",
        "\n",
        "# assessing performance of the model using k-fold cross validation\n",
        "scores = cross_val_score(logreg, input_features, output_var, cv=5)\n",
        "\n",
        "# performance in each fold\n",
        "print(\"Accuracies in each fold: \\n\" , scores)\n",
        "# average performance across all folds\n",
        "print(\"Average Accuracy across the folds: %0.2f\" % (scores.mean()))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracies in each fold: \n",
            " [0.92982456 0.93859649 0.96491228 0.93859649 0.95575221]\n",
            "Average Accuracy across the folds: 0.95\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJTMoW36peFz",
        "colab_type": "text"
      },
      "source": [
        "## Cross-validation and checking generalizability of the model\n",
        "After training a machine learning model, we need to check its generalizability and making sure it is not just good in prediction of training set but is capable of predicting new data points. In previous projects we splitted the data to 2 parts, training and test set. We can go one step further and repeat this splitting across the dataset so that every single data point is considered in one of the test (better to be said validation) sets. This process is called k-fold cross-validation. For example in case of 5-fold cross-validation, the dataset is splitted to 5 chunks and the model is trained in 4 out of 5 chunk and tested on the remianing chunk. The test chunk is then rotated so taht every chunk is conisidered once for testing the model. Then we can get average performance of the model in the tested chunks.\n",
        "\n",
        "Now we can implement the same modeling using different k values and compare them.\n",
        "\n",
        "Note. Lack (or low level) of generalizability of a trained model to new data points is called overfitting."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MJxm1JspjN0",
        "colab_type": "code",
        "outputId": "d33cd630-6c42-4493-fa32-038921476215",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "source": [
        "def kCV(model, input_df, output, k):\n",
        "  \n",
        "  scores = []\n",
        "  for k_iter in range(0,len(k)):\n",
        "    scores.append(cross_val_score(model, input_features, output_var, cv=k[k_iter]))\n",
        "    # barplot across different folds for each k value\n",
        "    plt.bar(k_iter+1+np.arange(0,len(scores[-1]))/50,height = scores[-1], width = 0.05)\n",
        "\n",
        "  # specifying parameters of the plot\n",
        "  plt.ylim(0.9, 1)\n",
        "  plt.ylabel(\"accuracy across folds\")\n",
        "  plt.xlabel(\"k values\")\n",
        "  plt.xticks([k_iter + 1 + k[k_iter]/100 for k_iter in range(0,len(k))], [str(k_iter) for k_iter in k])\n",
        "  plt.show()\n",
        "\n",
        "  # returning scores\n",
        "  return scores\n",
        "\n",
        "scores = kCV(model = logreg,\n",
        "             input_df = input_features,\n",
        "             output = output_var,\n",
        "             k = [3, 5, 10])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bydBTg5jte3D",
        "colab_type": "text"
      },
      "source": [
        "Now we can check the average score across different folds for each k value. Although the average accuracies are very close in this case, it does not mean they will be close for all tasks. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqiasG9zruYX",
        "colab_type": "code",
        "outputId": "e201fe67-6fbc-443f-856f-cb8ab8275f9d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print('average accuracies across the folds for each k value: {}'.format([np.mean(score) for score in scores]))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "average accuracies across the folds for each k value: [0.9437389770723104, 0.9455364073901569, 0.9437969924812031]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}