{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project3_logisticregression_breastcancer_Wisconsin.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yGUNM2BEsBQ5",
        "colab_type": "text"
      },
      "source": [
        "# Project objective\n",
        "This project is designed to review logistic regression method and its python implementation using Wisconsin breast cancer dataset.\n",
        "\n",
        "Information about the dataset, some technical details about the used machine learning method(s) and mathematical details of the quantifications approaches are provided in the code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjtJFxdsNh05",
        "colab_type": "text"
      },
      "source": [
        "# Packages we work with in this notebook\n",
        "We are going to use the following libraries and packages:\n",
        "\n",
        "* **numpy**: NumPy is the fundamental package for scientific computing with Python. (http://www.numpy.org/)\n",
        "* **sklearn**: Scikit-learn is a machine learning library for Python programming language. (https://scikit-learn.org/stable/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57oB2idEgr-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sklearn as sk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb1Zm7ARN5D5",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to the dataset\n",
        "\n",
        "**Name**: Wisconsin breast cancer dataset\n",
        "\n",
        "**Summary**: Identifying if there is a malignant tumor or not using features that are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass.\n",
        "\n",
        "**number of features**: 30 (real, positive) \n",
        "\n",
        "**Number of data points (instances)**: 569\n",
        "\n",
        "**dataset accessibility**: Dataset is available as part of sklearn package.\n",
        "\n",
        "**Link to the dataset**: http://archive.ics.uci.edu/ml/datasets/breast+cancer+wisconsin+(diagnostic)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjBnejgpP0Gr",
        "colab_type": "text"
      },
      "source": [
        "## Loading the dataset and separating features and labels\n",
        "The dataset is available as part of sklearn package. Hence, we do not need to import the data directly from UCI ML repository. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RILQWrhjQUtF",
        "colab_type": "code",
        "outputId": "50035491-ada1-4c46-a99d-48c2aefed3b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "\n",
        "# Loading breast cancer data\n",
        "target_dataset = load_breast_cancer()\n",
        "\n",
        "# separating feature arrays of pixel values (X) and labels (y) \n",
        "input_features = target_dataset.data\n",
        "output_var = target_dataset.target\n",
        "# printing number of features (pixels) and data points \n",
        "n_samples, n_features = input_features.shape\n",
        "print(\"number of samples (data points):\", n_samples)\n",
        "print(\"number of features:\", n_features)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples (data points): 569\n",
            "number of features: 30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qgejl_XWhWqN",
        "colab_type": "text"
      },
      "source": [
        "## Splitting data to training and testing sets\n",
        "\n",
        "We need to split the data to train and test, if we do not have a separate dataset for validation and/or testing, to make sure about gneralizability of the model we train.\n",
        "\n",
        "**test_size**: Traditionally, 30%-40% of the dataset cna be used for test set. If you split the data to train, validation and test, you can use 60%, 20% and 20% of teh dataset, respectively.\n",
        "\n",
        "**Note.**: We need the validation and test sets to be big enough for checking genralizability of our model. At the same time we would like to have as much data as possible in the training set to train a better model.\n",
        "\n",
        "**random_state** as the name suggests, is used for initializing the internal random number generator, which will decide the splitting of data into train and test indices in your case.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3L9BbkSg2vp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(input_features, output_var, test_size=0.30, random_state=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0Fi1jpVkbhC",
        "colab_type": "text"
      },
      "source": [
        "## Building the supervised learning model\n",
        "We want to build a binary classification model as the output variable is categorical with 2 classes. Here we build a simple logistic regression model.\n",
        "\n",
        "### Logistic regression\n",
        "If we have set of features X1 to Xn, y can be obtained as:\n",
        "\\begin{equation*} y=b0+b1X1+b2X2+...+bnXn\\end{equation*}\n",
        "\n",
        "where y is the predicted value obtained by weighted sum of the feature values.\n",
        "\n",
        "Then probability of each class (for example if there is a malignant tumor) can be obtained using the logistic function \n",
        "\n",
        "\\begin{equation*} p(class=malignant)=\\frac{1}{(1+exp(-y))} \\end{equation*}\n",
        "\n",
        "Based on the given class labels and the features given in the trainign data, coefficients b0 to bn can be ontained during the optimization process.\n",
        "\n",
        "b0 to bn are fixed for all samples while X1 to Xn are feature values specific to each sample. Hence, the logistic function will give us probability of each class assigned to each sample. Finally, the model will choose the class with the highest probability for each sample.\n",
        "\n",
        "\n",
        "**Note.** The logistic regression model is parametric and the parameters are the regression coefficiets b0 to bn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj3SSteMkxb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression \n",
        "\n",
        "# Create logistic regression object\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# Train the model using the training sets\n",
        "logreg.fit(X_train, y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zUWtodtDmFAW",
        "colab_type": "text"
      },
      "source": [
        "## Prediction of test (or validation) set\n",
        "We now have to use the trained model to predict y_test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KRQpG2vykzqX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make predictions using the testing set\n",
        "y_pred = logreg.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUHXoiaemXai",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating performance of the model\n",
        "We need to assess performance of the model using the predictions of the test set. We use accuracy and balanced accuracy. Here are their definitions:\n",
        "\n",
        "* **recall** in this context is also referred to as the true positive rate or sensitivity\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "$${\\displaystyle {\\text{recall}}={\\frac {tp}{tp+fn}}\\,} $$\n",
        "\n",
        " \n",
        "\n",
        "* **specificity** true negative rate\n",
        "\n",
        "\n",
        "\n",
        "$${\\displaystyle {\\text{true negative rate}}={\\frac {tn}{tn+fp}}\\,}$$\n",
        "\n",
        "* **accuracy**: This measure gives you a sense of performance for all the classes together as follows:\n",
        "\n",
        "$$ {\\displaystyle {\\text{accuracy}}={\\frac {tp+tn}{tp+tn+fp+fn}}\\,}$$\n",
        "\n",
        "\n",
        "\\begin{equation*} accuracy=\\frac{number\\:of\\:correct\\:predictions}{(total\\:number\\:of\\:data\\:points (samples))} \\end{equation*}\n",
        "\n",
        "\n",
        "* **balanced accuracy**: This measure gives you a sense of performance for all the classes together as follows:\n",
        "\n",
        "$${\\displaystyle {\\text{balanced accuracy}}={\\frac {recall+specificity\n",
        "}{2}}\\,}$$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAqcUM5Bmb2d",
        "colab_type": "code",
        "outputId": "5b7ab04b-a6e0-462d-a102-999782d79a88",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(\"accuracy of the predictions:\", metrics.accuracy_score(y_test, y_pred))\n",
        "print(\"blanced accuracy of the predictions:\", metrics.balanced_accuracy_score(y_test, y_pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "accuracy of the predictions: 0.9532163742690059\n",
            "blanced accuracy of the predictions: 0.9453800298062593\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8d5eJVRm2yO",
        "colab_type": "text"
      },
      "source": [
        "## Extracting the coefficient of the model\n",
        "The trained logistic regresseion model predicts the class of a datapoint as a fucntion of linear combination of feature values. Hence, each feature has a coefficient in this linear combination for predicting output variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ELrsRLImqtM",
        "colab_type": "code",
        "outputId": "9833a850-5c66-4000-f16f-00cc015049ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 99
        }
      },
      "source": [
        "print('Coefficients: {}'.format(logreg.coef_))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Coefficients: [[ 0.80188312  0.47135725  0.34246283 -0.02092841 -0.02696836 -0.13034695\n",
            "  -0.1897339  -0.08169113 -0.03612479 -0.0058486   0.04197023  0.44695641\n",
            "   0.11623421 -0.10294458 -0.00241085 -0.02734028 -0.04143775 -0.0105686\n",
            "  -0.00729451 -0.00227194  0.91413767 -0.52889934 -0.28273719 -0.00835908\n",
            "  -0.04723636 -0.39423874 -0.5180321  -0.1517702  -0.11723418 -0.03670763]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}