{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project9_randomforest_UCI_digitimage.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rSgMcG8-wvY",
        "colab_type": "text"
      },
      "source": [
        "# Project objective\n",
        "This project is designed to review random forest method and its python implementation using UCI hand-written digit dataset.\n",
        "\n",
        "Information about the dataset, some technical details about the used machine learning method(s) and mathematical details of the quantifications approaches are provided in the code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjtJFxdsNh05",
        "colab_type": "text"
      },
      "source": [
        "# Packages we work with in this notebook\n",
        "We are going to use the following libraries and packages:\n",
        "\n",
        "* **numpy**: NumPy is the fundamental package for scientific computing with Python. (http://www.numpy.org/)\n",
        "* **sklearn**: Scikit-learn is a machine learning library for Python programming language. (https://scikit-learn.org/stable/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57oB2idEgr-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import sklearn as sk"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb1Zm7ARN5D5",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to the dataset\n",
        "\n",
        "**Name**: UCI ML digit image data\n",
        "\n",
        "**Summary**: Images of hand-written digits in UCI ML repository\n",
        "\n",
        "**number of features**: 8*8(64) pixels (features)\n",
        "\n",
        "**Number of data points (instances)**: 1797\n",
        "\n",
        "**dataset accessibility**: Dataset is available as part of sklearn package.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjBnejgpP0Gr",
        "colab_type": "text"
      },
      "source": [
        "## Loading the dataset and separating features and labels\n",
        "The dataset is available as part of sklearn package. Hence, we do not need to import the data directly from UCI ML repository. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RILQWrhjQUtF",
        "colab_type": "code",
        "outputId": "91f62b01-44f9-44f7-adad-f30c1c83b5af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn import datasets\n",
        "\n",
        "# Loading digit images\n",
        "digits = datasets.load_digits()\n",
        "# separating feature arrays of pixel values (X) and labels (y) \n",
        "input_features = digits.data\n",
        "output_var = digits.target\n",
        "# printing number of features (pixels) and data points \n",
        "n_samples, n_features = input_features.shape\n",
        "print(\"number of samples (data points):\", n_samples)\n",
        "print(\"number of features:\", n_features)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of samples (data points): 1797\n",
            "number of features: 64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B8CRknwb3Izp",
        "colab_type": "text"
      },
      "source": [
        "## Splitting data to training and testing sets\n",
        "\n",
        "We need to split the data to train and test, if we do not have a separate dataset for validation and/or testing, to make sure about generalizability of the model we train.\n",
        "\n",
        "**test_size**: Traditionally, 30%-40% of the dataset cna be used for test set. If you split the data to train, validation and test, you can use 60%, 20% and 20% of teh dataset, respectively.\n",
        "\n",
        "**Note.**: We need the validation and test sets to be big enough for checking generalizability of our model. At the same time we would like to have as much data as possible in the training set to train a better model.\n",
        "\n",
        "**random_state** as the name suggests, is used for initializing the internal random number generator, which will decide the splitting of data into train and test indices in your case.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-MQLTHE3JUN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(input_features, output_var, test_size=0.30, random_state=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIebwbGB3Pss",
        "colab_type": "text"
      },
      "source": [
        "## Building the supervised learning model\n",
        "We want to build a multi-class classification model as the output variable is categorical with 10 classes. Here we build a random forest model.\n",
        "\n",
        "### Decision tree\n",
        "A decision tree is built starting from the best feature splitting the data points to 2 purest possible groups. Then each group is splitted again by next best features for purification of groups. Although this process can be continued till getting to 100% purity (having only one class) in each group, it would probably lower than generalizability of the model. Hence, we usually cut the tree before getting to 100% purity.\n",
        "\n",
        "### Random forest\n",
        "Decision trees usually have high variance, meaning their prediction performance varies largely between datasets. To overcome this issue we can rely on concept of ensemble learning. In ensemble learning we want to use wisdom of crowd instead of single classifier. For example, random forest as an ensemble model uses multiple decision trees to predict class of each data point. Here is the process of bulding a random forest model:\n",
        "\n",
        "1) Randomly sampling data points with replacement (bootstrapping)\n",
        "\n",
        "2) Randomly selecting the features \n",
        "\n",
        "3) Build a decision tree using the randomly selected data points and features in steps 1 and 2.\n",
        "\n",
        "4) Building multiple decision trees as decsribed in steps 1 to 3\n",
        "\n",
        "5) Using majority vote of all the decision trees as the identified class for a given data point\n",
        "\n",
        "Note. We don't need to write code for these steps but they will be done automatically when using random forest in python. But we need to know how it works. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7-0Y0a93c0R",
        "colab_type": "code",
        "outputId": "58defadb-861c-4af5-ae52-5ff88ba9fb86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier \n",
        "\n",
        "# Create logistic regression object\n",
        "rf = RandomForestClassifier()\n",
        "\n",
        "# Train the model using the training sets\n",
        "rf.fit(X_train, y_train)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kw5xChiS5mWv",
        "colab_type": "text"
      },
      "source": [
        "## Prediction of test (or validation) set\n",
        "We now have to use the trained model to predict y_test."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ALm8Q6k5mw3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make predictions using the testing set\n",
        "y_pred = rf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bjMC2z0Y5zHk",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating performance of the model\n",
        "We need to assess performance of the model using the predictions of the test set. We use F1 score for this model. Here is the definition of F1 score:\n",
        "\n",
        "\n",
        "* **F1 score** is the harmonic mean of precision and recall as follows\n",
        "\n",
        "$${\\displaystyle {\\text{F1}}={\\frac {2}{\\frac {1}{precision}+ \\frac {1}{recall}}}\\,} $$\n",
        "\n",
        "where \n",
        "\n",
        "* **precision** is the fraction of true positives out of all the positive predictions\n",
        "\n",
        "$${\\displaystyle {\\text{precision}}={\\frac {tp}{tp+fp}}\\,} $$\n",
        "\n",
        "* **recall** is also referred to as the true positive rate or sensitivity\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "$${\\displaystyle {\\text{recall}}={\\frac {tp}{tp+fn}}\\,} $$\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AVaDA0LM8PbJ",
        "colab_type": "code",
        "outputId": "ed9430ed-b2ee-4903-cde3-9071a5ea07b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(\"F1 score of the predictions:\", metrics.f1_score(y_test, y_pred, average=None))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "F1 score of the predictions: [0.98275862 0.95412844 0.99130435 0.95575221 0.97674419 0.97674419\n",
            " 0.97826087 0.98305085 0.92156863 0.96      ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_ucoJSd8Vlo",
        "colab_type": "text"
      },
      "source": [
        "**Note** We cannot use default value of \"average\" parameter in metrics.f1_score which is \"binary\" as it is designed for binary classification while we are dealing with multi-class classification here. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3Nbytxb8lAU",
        "colab_type": "text"
      },
      "source": [
        "### Interpretation of results\n",
        "As we can see, we could achieve more than 0.94 F1 score for all the classes (digits 0 to 9). However, there is still a gap between class 0 (images of digit 0) and classes 8 and 9 (images of digits 8 and 9). Hence, we need to figure out if the lower F1 scores of classes 8 and 9 are due to lower precision or recall or both. As we can see in the following results, precision and recall of class 8 are the same while precision of class 9 is higher than its recall. Interestingly, there are classes which their precision is higher than their recall (such as classes 0 and 2) while the reverse is true for some other classes (such as class 9)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f92lALID9WSI",
        "colab_type": "code",
        "outputId": "3d6edfea-61ae-4657-e9a4-067cee985286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "source": [
        "print(\"precision of the predictions:\", metrics.precision_score(y_test, y_pred, average=None))\n",
        "print(\"recall of the predictions:\", metrics.recall_score(y_test, y_pred, average=None))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "precision of the predictions: [0.98275862 0.9122807  1.         1.         0.97674419 0.96923077\n",
            " 1.         0.98305085 0.90384615 0.96      ]\n",
            "recall of the predictions: [0.98275862 1.         0.98275862 0.91525424 0.97674419 0.984375\n",
            " 0.95744681 0.98305085 0.94       0.96      ]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}