{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "project13_affinitypropagation_ccle.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FME7vf0gMG0Y",
        "colab_type": "text"
      },
      "source": [
        "# Project objective\n",
        "In this project, we review affinity propagation for clustering #cancer cell lines tissue of origin of# cancer cell lines using their gene expression provided in #cancer cell line encyclopedia dataset. You can also learn about homogeneity, completeness and V-measure as different statistical measures for assessing performance of a clustering model.\n",
        "\n",
        "Information about the dataset, some technical details about the used machine learning method(s) and mathematical details of the quantifications approaches are provided in the code. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjtJFxdsNh05",
        "colab_type": "text"
      },
      "source": [
        "# Packages we work with in this notebook\n",
        "We are going to use the following libraries and packages:\n",
        "\n",
        "* **numpy**: NumPy is the fundamental package for scientific computing with Python. (http://www.numpy.org/)\n",
        "* **sklearn**: Scikit-learn is a machine learning library for Python programming language. (https://scikit-learn.org/stable/)\n",
        "* **Seaborn**: Seaborn is a visualization library in Python. https://seaborn.pydata.org/\n",
        "* **pandas**: Pandas provides easy-to-use data structures and data analysis tools for Python. (https://pandas.pydata.org/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "57oB2idEgr-g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import sklearn as sk"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb1Zm7ARN5D5",
        "colab_type": "text"
      },
      "source": [
        "# Introduction to the dataset\n",
        "\n",
        "**Name**: Cancer Cell Line Encyclopedia dataset\n",
        "\n",
        "**Summary**: Identifying tissue of origin of cancer cell lines using their gene expression. Cell lines from 6 tissues were chosen for this code including: breast, central_nervous_system, haematopoietic_and_lymphoid_tissue, large_intestine, lung, skin\n",
        "\n",
        "**number of features**: 500 (real, positive) \n",
        "Top 500 genex based on variance of their expression in the dataset is chosen. The right way to select the features is to do it only on the training set to eliminate information leak from test set. But to simplify the process for the sake of this teaching code, we use all the dataset.\n",
        "\n",
        "**Number of data points (instances)**: 550\n",
        "\n",
        "**dataset accessibility**: Dataset is available as part of PharmacoGx R package (https://www.bioconductor.org/packages/release/bioc/html/PharmacoGx.html)\n",
        "\n",
        "**Link to the dataset**: https://portals.broadinstitute.org/ccle\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QjBnejgpP0Gr",
        "colab_type": "text"
      },
      "source": [
        "## Importing the dataset\n",
        "We can import the dataset in multiple ways\n",
        "\n",
        "**Colab Notebook**: You can download the dataset file (or files) from the link (if provided) and uploading it to your google drive and then you can import the file (or files) as follows:\n",
        "\n",
        "**Note.** When you run the following cell, it tries to connect the colab with google derive. Follow steps 1 to 5 in this link (https://www.marktechpost.com/2019/06/07/how-to-connect-google-colab-with-google-drive/) to complete the process. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RILQWrhjQUtF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "# This path is common for everybody\n",
        "# This is the path to your google drive\n",
        "input_path = '/content/gdrive/My Drive/'\n",
        "# reading the data (target)\n",
        "target_dataset_features = pd.read_csv(input_path + 'CCLE_ExpMat_Top500Genes.csv', index_col=0)\n",
        "target_dataset_output = pd.read_csv(input_path + 'CCLE_ExpMat_Phenotype.csv', index_col=0)\n",
        "# Transposing the dataframe to put features in the dataframe columns\n",
        "target_dataset_features = target_dataset_features.transpose()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_xyaPc17CAD",
        "colab_type": "text"
      },
      "source": [
        "**Local directory**: In case you save the data in your local directory, you need to change \"input_path\" to the local directory you saved the file (or files) in.\n",
        "\n",
        "**GitHub**: If you use my GitHub (or your own GitHub) repo, you need to change the \"input_path\" to where the file (or files) exist in the repo. For example, when I clone ***ml_in_practice*** from my GitHub, I need to change \"input_path\" to 'data/' as the file (or files) is saved in the data dicretory in this repository. \n",
        "\n",
        "**Note.**: You can also clone my ***ml_in_practice*** repository (here: https://github.com/alimadani/ml_in_practice) and follow the same process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TgJ6VcY-998e",
        "colab_type": "text"
      },
      "source": [
        "## Making sure about the dataset characteristics (number of data points and features)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k4Twci0U9-3S",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "75d5013e-8cf1-4614-fc0f-bd5719213c4b"
      },
      "source": [
        "print('number of features: {}'.format(target_dataset_features.shape[1]))\n",
        "print('number of data points: {}'.format(target_dataset_features.shape[0]))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of features: 500\n",
            "number of data points: 550\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mxy4Si3PJfLF",
        "colab_type": "text"
      },
      "source": [
        "##Data preparation\n",
        "\n",
        "We need to prepare the dataset for machine learnign modeling. Here we need to convert categorical columns (strings) to integeres. Those columns can be used as output variable."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OdJjVNAnJgBl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# tissueid is the column that contains tissue type information\n",
        "output_var_names = target_dataset_output['tissueid']\n",
        "# converting tissue names to labels\n",
        "from sklearn import preprocessing\n",
        "le = preprocessing.LabelEncoder()\n",
        "\n",
        "le.fit(output_var_names)\n",
        "output_var = le.transform(output_var_names)\n",
        "\n",
        "# we would like to use all the features as input features of the model\n",
        "input_features = target_dataset_features"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gs9YzbD2LCum",
        "colab_type": "text"
      },
      "source": [
        "### Normalizing feature values\n",
        "Normalizing feature values usually helps us for developing a better machine learning model. Here we normalize the data by deducting mean of each feature column from each one of its values and then divide them by standard deviation of the same feature column. This normalization process change mean of each feature (column) to zero and its standard deviation to one. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XxUZ41kwLRiS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import preprocessing\n",
        "\n",
        "input_features = pd.DataFrame(preprocessing.scale(input_features)) "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0Fi1jpVkbhC",
        "colab_type": "text"
      },
      "source": [
        "## Building the unsupervised learning (clustering) model\n",
        "We want to build a clustering model using affinity propagation. As it is an unsupervise process, we do not need output values of datapoints for the modeling.\n",
        "\n",
        "### Affinity propagation\n",
        "Clustering using k-means can be summarized in 6 main steps:\n",
        "\n",
        "1) Number of clusters (k) does not need to be determined\n",
        "\n",
        "2) Determining pairwise similarity between data points\n",
        "\n",
        "* Similarity between data points i and j: negative euclidean distance between data points i and j\n",
        "\n",
        "3) Determines clusters and representative data points for the clusters (exemplars)\n",
        "\n",
        "4) Iterative massage passing\n",
        "Data points compete to become exemplars\n",
        "Exemplars are real data points not centers as in k-means\n",
        "\n",
        "5) Initialization independent\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZI1HcRnb5oB",
        "colab_type": "text"
      },
      "source": [
        "**Hyperparameters of affinity propagation:**\n",
        "\n",
        "* **max_iter**: Maximum number of iterations\n",
        "\n",
        "* **convergence_iter**: Number of iterations with no change in the number of estimated clusters that stops the convergence.\n",
        "\n",
        "* **damping (ranges between 0.5 and 1)**: Damping factor is the extent to which the current value is maintained relative to incoming values."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fj3SSteMkxb2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "acbb8fa1-5a8a-439f-8e39-e6ddbe7a7084"
      },
      "source": [
        "from sklearn import cluster\n",
        "\n",
        "# Create logistic regression object\n",
        "clustmodel = cluster.AffinityPropagation(max_iter=500, convergence_iter = 15, damping = 0.97)\n",
        "\n",
        "# Train the model using the training sets\n",
        "clustmodel.fit(input_features)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "AffinityPropagation(affinity='euclidean', convergence_iter=15, copy=True,\n",
              "                    damping=0.97, max_iter=500, preference=None, verbose=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BCt19vhFNqbf",
        "colab_type": "text"
      },
      "source": [
        "### Number of clusters\n",
        "\n",
        "As k (number of clusters) are not determined as an input, we cannot expect specific number of cluster as the results of affinity propagation clustering. Let's check how many clusters affinity propagation identtified in our dataset and compare it with the actual number of groups in the dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-m-y8wMN7xP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "d61e382a-b3e3-4a65-e1b0-b65bf8c76b72"
      },
      "source": [
        "print('number of unique clusters: {}'.format(len(np.unique(clustmodel.labels_))))\n",
        "print('number of true groups in the dataset: {}'.format(len(np.unique(output_var))))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "number of unique clusters: 21\n",
            "number of true groups in the dataset: 6\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u8M2D_lViO9s",
        "colab_type": "text"
      },
      "source": [
        "**Note.** We have 21 clusters instead of original 6 tissue types. This could be due to some underlying groupings within each class. You can play with \"damping\" parameter and see how number of clusters and performance of the clustering will be changed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xUHXoiaemXai",
        "colab_type": "text"
      },
      "source": [
        "## Evaluating performance of the model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uh6tW5m0DJDq",
        "colab_type": "text"
      },
      "source": [
        "We can have a summary measure like V-measure that tells us about the performance of the clustering. The V-measure is the harmonic mean (reciprocal of the arithmetic mean of the reciprocals) between homogeneity and completeness:\n",
        "\n",
        "\n",
        "* **V-measure (ranges between 0 and 1)**\n",
        "\n",
        "\n",
        "\\begin{equation*} V = \\frac{(1+\\beta)*homogeneity*completeness}{\\beta*homogeneity +completeness}\\end{equation*}\n",
        "\n",
        "* **Homogeneity (ranges between 0 and 1)**: If homogeneity is 1, it means that every cluster contains only elements that are members of the same class while 0 homogeneity means having 1 cluster of all data points. \n",
        "\n",
        "* **Completeness (ranges between 0 and 1)**: If completeness is 1, it means that all elements of any given class are in the same cluster and 0 means that there is only one class and every element in it is assigned to a different cluster.\n",
        "\n",
        "Learn more about **Homogeneity** and **Completeness** here: https://www.aclweb.org/anthology/D07-1043.pdf\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cAqcUM5Bmb2d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "5cf61c78-8a7d-41a0-f195-e74d64c59d70"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "print(\"Homogeneity of the identified clusters:\", metrics.homogeneity_score(output_var,clustmodel.labels_))\n",
        "print(\"Completeness of the identified clusters:\", metrics.completeness_score(output_var,clustmodel.labels_))\n",
        "print(\"V-measure of the identified clusters:\", metrics.v_measure_score(output_var,clustmodel.labels_))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Homogeneity of the identified clusters: 0.7449723315176991\n",
            "Completeness of the identified clusters: 0.4201893794737535\n",
            "V-measure of the identified clusters: 0.5373150503532702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xZjRnQYmOkcj",
        "colab_type": "text"
      },
      "source": [
        "As we can see, completeness of the clustering is low, although homogeneity could be acceptable. One reason could be the difference in number of clusters (21) and original classes (6) in the dataset."
      ]
    }
  ]
}